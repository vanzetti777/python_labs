# python_labs

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 1
## –ó–∞–¥–∞–Ω–∏–µ 1
```python
a=input("–ò–º—è:")
b=int(input("–í–æ–∑—Ä–∞—Å—Ç: "))
c=b+1
print(f"–ü—Ä–∏–≤–µ—Ç, ",a,"! –ß–µ—Ä–µ–∑ –≥–æ–¥ —Ç–µ–±–µ –±—É–¥–µ—Ç",c)
```
![!\[alt text\](image1/01.png)](img/image1/01.png)
## –ó–∞–¥–∞–Ω–∏–µ 2
```python
a=input('a: ')
a=a.replace(',','.')
a=float(a)
b=input('b: ')
b=b.replace(',','.')
b=float(b)
print(f"sum={a+b}; avg={(a+b)/2:.2f}")
```
![!\[alt text\](image1/02.png)](img/image1/02.png)
## –ó–∞–¥–∞–Ω–∏–µ 3
```python
price=float(input('—Ü–µ–Ω–∞, —Ä: '))
discount=float(input('—Å–∫–∏–¥–∫–∞, %: '))
vat=float(input('–Ω–¥—Å, %:'))
base = price * (1 - discount/100)
vat_amount = base * (vat/100)
total = base + vat_amount
print(f"–±–∞–∑–∞ –ø–æ—Å–ª–µ —Å–∫–∏–¥–∫–∏:{base:.2f} —Ä")
print(f"–Ω–¥—Å:{vat_amount:.2f} —Ä")
print(f"–∏—Ç–æ–≥–æ –∫ –æ–ø–ª–∞—Ç–µ:{total:.2f} —Ä")
```
![!\[alt text\](image1/03.png)](img/image1/03.png)
## –ó–∞–¥–∞–Ω–∏–µ 4
```python
m=int(input("–º–∏–Ω—É—Ç—ã: "))
print(f"{m//60}:{m-(60*(m//60)):02d}")
```
![!\[alt text\](image1/04.png)](img/image1/04.png)
## –ó–∞–¥–∞–Ω–∏–µ 5
```python
name=str(input("–§–ò–û: "))
print(f"–∏–Ω–∏—Ü–∏–∞–ª—ã: {(name.split()[0])[0]}{(name.split()[1])[0]}{(name.split()[2])[0]}.")
name=name.replace(' ','')
print(f"–¥–ª–∏–Ω–∞: {len(name)+2}")
```
![!\[alt text\](<image1/image copy.png>)](<img/image1/image copy.png>)
## –ó–∞–¥–∞–Ω–∏–µ 6
```python
n=int(input('in_1: '))
k=1
och=0
zao=0
for i in range(n):
    k+=1
    name1, name2,voz , obu = (input(f'in{k}: ')).split()
    if obu=="True":
        och+=1
    else:
        zao+=1
print(f'out: {och},{zao}')
```
![!\[alt text\](image1/image.png)](img/image1/image.png)


# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 2
## –ó–∞–¥–∞–Ω–∏–µ 1
```python
test1=[3,-1,5,5,0]
test2=[42]
test3=[-5, -2, -9]
test4=[]
test5=[1.5, 2, 2.0, -3.1]
def min_max(nums: list[float | int]) -> tuple[float | int, float | int]:
    #–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
    if len(nums)==0:
        print('ValueError')
    else:
        list2=(min(nums),max(nums))
        print(list2)
print(min_max(test1))
print(min_max(test2))
print(min_max(test3))
print(min_max(test4))
print(min_max(test5))
```

![!\[alt text\](<image2/image 2.1.1.png>)](<img/image2/image 2.1.1.png>)

```python
test1=[3, 1, 2, 1, 3] 
test2=[]
test3=[-1, -1, 0, 2, 2]
test4=[1.0, 1, 2.5, 2.5, 0]
def unique_sorted(nums: list[float | int]) -> list[float | int]:
    #—Å–æ–∑–¥–∞–µ–º 2 —Å–ø–∏—Å–∫–∞
    list_int=[]
    list_float=[]
    #—Ä–∞–∑–¥–µ–ª—è—é –∏–Ω—Ç –∏ —Ñ–ª–æ–∞—Ç 
    for i in nums:
        if type(i)==int:
            list_int.append(i)
        else:
            list_float.append(i)
    res1=[x for x in list_float if int(x) in list_int]#–¥–æ–±–∞–≤–ª—è—é —Ñ–ª–æ–∞—Ç –µ—Å–ª–∏ –æ–Ω –≤ –∏–Ω—Ç –∑–Ω–∞—á–µ–Ω–∏–∏ –µ—Å—Ç—å –≤ –∏–Ω—Ç —Å–ø–∏—Å–∫–µ
    res2=[x for x in list_int if float(x) not in list_float]#–¥–æ–±–∞–≤–ª—è—é –∏–Ω—Ç –µ—Å–ª–∏ –≤–æ —Ñ–ª–æ–∞—Ç –µ–≥–æ –Ω–µ—Ç
    print(sorted(set(res1+res2+list_float)))
print(unique_sorted(test1))
print(unique_sorted(test2))
print(unique_sorted(test3))
print(unique_sorted(test4))
```
![!\[alt text\](<image2/image 2.1.2.png>)](<img/image2/image 2.1.2.png>)

```python
test1=[[1, 2], [3, 4]]
test2=([1, 2], (3, 4, 5))
test3=[[1], [], [2, 3]]
test4=[[1, 2], "ab"]

def flatten(mat: list[list | tuple]) -> list:
    #—Å–æ–∑–¥–∞—é 2 —Å–ø–∏—Å–∫–∞ —á—Ç–æ–±—ã –≤—Å–µ –∑–∞–±—Ä–∞—Ç—å –≤ —Å–ø–∏—Å–∫–∏
    list1=[]
    list2=[]
    count=0
    #–ø–µ—Ä–µ–±–∏—Ä–∞—é —ç–ª–µ–º–µ–Ω—Ç—ã —Å–ø–∏—Å–∫–∞/–∫–æ—Ä—Ç–µ–∂–∞
    for enum1 in mat:
        #–ø–µ—Ä–µ–±–∏—Ä–∞—é —ç–ª–µ–º–µ–Ω—Ç—ã –≤ —ç–ª–µ–º–µ–Ω—Ç–∞—Ö..–∏ –≤—Å–µ –¥–æ–±–∞–≤–ª—è—é –≤ 1 —Å–ø–∏—Å–æ–∫
        for enum2 in enum1:
            list1.append(enum2)
            #–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –º–∞—Ç—Ä–∏—á–Ω–æ—Å—Ç—å —ç–ª–µ–º–µ–Ω—Ç–∞
            if type(enum2)==int:
                count+=1
            if count==len(list1):
                list2.append(enum2)
            else:
                print('TypeError')
    if count==len(list1):
        print(list2)

print(flatten(test1))
print(flatten(test2))
print(flatten(test3))
print(flatten(test4))
```
![!\[alt text\](<image2/image 2.1.3.png>)](<img/image2/image 2.1.3.png>)

##–ó–∞–¥–∞–Ω–∏–µ 2
```python
test1=[[1, 2, 3]]
test2=[[1], [2], [3]] 
test3=[[1, 2], [3, 4]] 
test4=[] 
test5=[[1, 2], [3]]
def transpose(mat: list[list[float | int]]) -> list[list[float | int]]:
    #–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—É—Å—Ç–æ–π –º–∞—Ç—Ä–∏—Ü—ã
    if not mat:
        return []
    #–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ä–∞–≤–Ω—ã–µ –µ–ª–µ–º–µ–Ω—Ç—ã
    row1st = len(mat[0])
    for row in mat:
        if len(row) != row1st:
            return ("ValueError")
    #—Ç—Ä–∞–Ω—Å–ø–æ–∑
    transp = []
    for col_index in range(len(mat[0])):
        row_new = []
        for row_index in range(len(mat)):
            row_new.append(mat[row_index][col_index])
        transp.append(row_new)
    return transp
print(transpose(test1))
print(transpose(test2))
print(transpose(test3))
print(transpose(test4))
print(transpose(test5))
```
![!\[alt text\](<image2/image 2.2.1.png>)](<img/image2/image 2.2.1.png>)

```python
test1=[[1, 2, 3], [4, 5, 6]] 
test2=[[-1, 1], [10, -10]] 
test3=[[0, 0], [0, 0]] 
test4=[[1, 2], [3]]
def row_sums(mat: list[list[float | int]]) -> list[float]:
    #–ø—Ä–æ–≤–µ—Ä—è—é –Ω–∞ –æ–¥–∏–Ω–∞–∫ –¥–ª–∏–Ω—É —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    for i in range(len(mat)-1):
        if len(mat[i])!=len(mat[i+1]):
            print("ValueError")
        else:
            #–±–µ—Ä—É —Å—É–º–º—É –ø–æ —ç–ª–µ–º–µ–Ω—Ç–∞–º —Å–ø–∏—Å–∫–∞
            return [sum(mat[i]),sum(mat[i+1])]
print(row_sums(test1))
print(row_sums(test2))
print(row_sums(test3))
print(row_sums(test4))          
```
![!\[alt text\](<image2/image 2.2.2.png>)](<img/image2/image 2.2.2.png>)

```python
test1=[[1, 2, 3], [4, 5, 6]]
test2=[[-1, 1], [10, -10]] 
test3=[[0, 0], [0, 0]] 
test4=[[1, 2], [3]]
def col_sums(mat: list[list[float | int]]) -> list[float]:
    #–ø—Ä–æ–≤–µ—Ä—è—é –ø–∞—Ä—ã –∏–∑ —Å–ø–∏—Å–∫–∞ –Ω–∞ –æ–¥–∏–Ω–∞–∫ –¥–ª–∏–Ω—É
    for enum1 in range(len(mat)-1):
        if len(mat[enum1])!=len(mat[enum1+1]):
            print("ValueError")
        else:
            #–±–µ—Ä—É —Å—É–º–º—É –ø–æ –∫–∞–∂–¥–æ–º—É —Å—Ç–æ–ª–±—Ü—É
            list1 = []
            for enum2 in zip(*mat): 
                list1.append(sum(enum2))
    return list1
print(col_sums(test1))
print(col_sums(test2))
print(col_sums(test3))
print(col_sums(test4))
```
![img/image2/image 2.2.3.png](<img/image2/image 2.2.3.png>)

## –ó–∞–¥–∞–Ω–∏–µ 3

```python
def format_record(rec: tuple[str, str, float]) -> str:
    #–ø—Ä–æ–≤–µ—Ä—è—é –Ω–∞ –ø—É—Å—Ç—ã–µ —è—á–µ–π–∫–∏
    if len(rec) != 3:
        return ValueError
    #–ø—Ä–æ–≤–µ—Ä—è—é –≥–ø–∞ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å
    if not isinstance(rec[2], (int, float)):
        return TypeError
    if rec[2] < 0 or rec[2] > 5.0:
        return ValueError
    #–ø—Ä–æ–≤–µ—Ä—è—é —Ñ–∏–æ, —Ä–∞–∑–¥–µ–ª—è—é –∏ –±–µ—Ä—É —Ç–æ–ª—å–∫–æ –±–æ–ª—å—à–∏–µ –±—É–∫–≤—ã
    if type(rec[0]) == str:
        e=rec[0].split()
        #–µ—Å–ª–∏ —Ñ–∏
        if len(e)==2:
            f=e[0].capitalize()+' '+(e[1].capitalize())[0]+'.'
        else:
            f=e[0].capitalize()+' '+ (e[1].capitalize())[0]+'.'+(e[2].capitalize())[0]+'.'
        res=f+','+' –≥—Ä.'+rec[1] + ', ' + f"{rec[2]:.2f}"
        print(res)
        

test1 = ("–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á", "BIVT-25", 4.6)
test2=("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä", "IKBO-12", 5.0) 
test3=("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 5.0) 
test4=("  —Å–∏–¥–æ—Ä–æ–≤–∞  –∞–Ω–Ω–∞   —Å–µ—Ä–≥–µ–µ–≤–Ω–∞ ", "ABB-01", 3.999)
test5=( "ABB-01", 3.999)
test6=("–ü–µ—Ç—Ä–æ–≤ –ü—ë—Ç—Ä –ü–µ—Ç—Ä–æ–≤–∏—á", "IKBO-12", 6.0) 
print(format_record(test1))
print(format_record(test2)) 
print(format_record(test3)) 
print(format_record(test4))  
print(format_record(test5)) 
print(format_record(test6)) 
```
![img/image2/image 2.3.png](<img/image2/image 2.3.png>)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 3
## –ó–∞–¥–∞–Ω–∏–µ 1
```python
testcase1="–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t"
testcase2="—ë–∂–∏–∫, –Å–ª–∫–∞" 
testcase3="Hello\r\nWorld" 
testcase4="  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  "
import re
def normalize(text: str, *, casefold: bool = True, yo2e: bool = True) -> str:
    # r'\s+' –∑–∞–º–µ–Ω—è–µ–º –≤—Å–µ –≤—Å–µ –ª–∏—à–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç—ã, –∑–∞–º–µ–Ω—è–µ—Ç –Ω–∞ –ø—Ä–æ–±–µ–ª
    text= re.sub(r'\s+', ' ', text).strip()
    text=text.casefold()
    text=text.replace('—ë','e')
    return text
    
print(normalize(testcase1))
print(normalize(testcase2))
print(normalize(testcase3))
print(normalize(testcase4))

testcase1="–ø—Ä–∏–≤–µ—Ç –º–∏—Ä" 
testcase2="hello,world!!!"
testcase3="–ø–æ-–Ω–∞—Å—Ç–æ—è—â–µ–º—É –∫—Ä—É—Ç–æ" 
testcase4="2025 –≥–æ–¥"
testcase5="emoji üòÄ –Ω–µ —Å–ª–æ–≤–æ"

import re
def tokenize(text: str) -> list[str]:
    shablon=r'\w+(?:-\w+)*'
    # –∏—â–µ—Ç –≤—Å–µ –ø–æ —à–∞–±–ª–æ–Ω—É –∏–∑ –Ω–æ—Ä–º —Ç–µ–∫—Å—Ç–∞ 
    tockens = (re.findall(shablon,normalize(text)))
    return tockens

print(tokenize(testcase1))
print(tokenize(testcase2))
print(tokenize(testcase3))
print(tokenize(testcase4))
print(tokenize(testcase5))

testcase1=["a","b","a","c","b","a"]
testcase2=["bb","aa","bb","aa","cc"]

def count_freq(tokens: list[str]) -> dict[str, int]:
    fdict={}
    #—Å–æ–∑–¥–∞–µ–º —Å–ª–æ–≤–∞—Ä—å
    for token in tokens:
        # –µ—Å–ª–∏ –≤ —Å–ª–æ–≤–∞—Ä–µ –µ—Å—Ç—å –Ω–∞–ø—Ä–∏–º–µ—Ä '–∞' —Ç–æ —Å—á–µ—Ç—á–∏–∫ "a" —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è 
        if token in fdict:
            fdict[token]+=1
        else:
            fdict[token]=1
    return fdict

#–£–ñ–ï –ü–û–°–õ–ï –°–û–ó–î–ê–ù–ò–Ø –°–õ–û–í–ê–†–Ø –ò–ó –≠–õ–ï–ú–ï–ù–¢–û–í
def top_n(freq: dict[str, int], n: int = 5) -> list[tuple[str, int]]:
    #–ø—Ä–µ–≤—Ä–∞—â–µ–º –≤ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è –≤ —Å–ø–∏—Å–∫–µ
    items = list(freq.items())
    # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–Ω–∞—á–∞–ª–∞ –ø–æ —É–±—ã–≤–∞–Ω–∏—é —á–∞—Å—Ç–æ—Ç—ã, –ø–æ—Ç–æ–º –ø–æ –∞–ª—Ñ
    sorted_items = sorted(items, key=lambda x: (-x[1], x[0]))
    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–µ N —ç–ª–µ–º–µ–Ω—Ç–æ–≤
    return sorted_items[:n]


print(count_freq(testcase1))
print(top_n(count_freq(testcase1)))
print(count_freq(testcase2))
print(top_n(count_freq(testcase2)))
```
![alt text](img/image3/03.01.png)
# –ó–∞–¥–∞–Ω–∏–µ 2
``` python
import sys
import text 

stdin = sys.stdin.read()
#–≤—Å–µ —Å–ª–æ–≤–∞ —Å–ø–∏—Å–∫–æ–º
allwords= text.tokenize(stdin)
#—É–Ω–∏–∫ —Å–ª–æ–≤–∞ —Å–ø–∏—Å–∫–æ–º
uniquewords=text.count_freq(allwords)
#—Å–ª–æ–≤–æ –∏ —á–∞—Å—Ç–æ—Ç–∞ —Å–ø–∏—Å–∫–æ–º
top= text.top_n(uniquewords,5)
print(f'–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(allwords)}')
print(f'–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(uniquewords)}')
print("–¢–æ–ø-5:")
for i in top:
    print(i[0]+':'+str(i[1])) 
```
![alt text](img/image3/03.02.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 4
## –ó–∞–¥–∞–Ω–∏–µ 1
### —Ñ—É–Ω–∫—Ü–∏–∏
```python
from pathlib import Path
import csv
from typing import Iterable, Sequence, Union 

def read_text(path: str | Path, encoding: str = "utf-8") -> str:
    #—á–∏—Ç–∞–µ—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –µ–≥–æ –∫–∞–∫ 1 —Å—Ç—Ä–æ–∫—É
    p = Path(path)
    if p.suffix.lower() != '.txt':
        raise ValueError('–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –∏—Å—Ö–æ–¥–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –Ω–µ txt')
    try:
        return p.read_text(encoding=encoding)
    
    except FileNotFoundError:
        raise FileNotFoundError
    
    except UnicodeDecodeError:
        raise UnicodeDecodeError
```

```python
def write_csv(rows: list[tuple | list], path: str | Path, header: tuple[str, ...] | None = None) -> None:
    p = Path(path)

    if p.suffix.lower() != '.csv':
        raise ValueError('–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≤—ã–≤–æ–¥–∞ –Ω–µ csv')
    
    rows = list(rows)
    #–µ—Å–ª–∏ –Ω–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ –±–µ–¥–µ–º –¥–ª–∏–Ω—É –ø–æ 1 —Å—Ç—Ä–æ—á–∫–µ
    if rows:
        if header is not None:
            expectlen = len(header)
        else:
            expectlen = len(rows[0])
        #–ø—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ —Å—Ç—Ä–æ–∫–∏, enumerate –ø—Ä–æ—Å—Ç–æ –∏–¥–µ—Ç –ø–æ —Å—Ç—Ä–æ–∫–∞–º
        for i, row in enumerate(rows):
            if len(row) != expectlen:
                raise ValueError
    # –µ—Å–ª–∏ –µ—Å—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫
    if header is not None and rows:
        if len(header) != len(rows[0]):
            raise ValueError
    #—à–∞–±–ª–æ–Ω
    with p.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        if header is not None:
            w.writerow(header)
        for r in rows:
            w.writerow(r)
```
–ø—Ä–∏ –±–æ–ª—å—à–∏—Ö —Ñ–∞–π–ª–∞—Ö —á–∏—Ç–∞–µ–º –ø–æ—Å—Ç—Ä–æ—á–Ω–æ, –Ω–µ –ø–µ—Ä–µ–¥–µ–ª—ã–≤–∞—è –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ –≤ —Å–ø–∏—Å–æ–∫

```python
def write_csv(rows: Iterable[Sequence], path: str | Path,
              header: tuple[str, ...] | None = None) -> None:
    p = Path(path)
    with p.open("w", newline="", encoding="utf-8") as f:
        w = csv.writer(f)
        if header is not None:
            w.writerow(header)

        for r in rows:
            w.writerow(r)
```

### –ø—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ –ø—É—Å—Ç—ã–µ —Ñ–∞–π–ª—ã, –æ—à–∫–∏–±–∫–∏, –¥—Ä—É–≥–∏–µ —Ñ–æ—Ä–º–∞—Ç—ã, –ê –¢–ê–ö–ñ–ï –ù–ê –¢–û –ß–¢–û WRITECSV –í–û–°–ü–†–ò–ù–ò–ú–ï–¢ –¢–û–õ–¨–ö–û TXT –ò –í–´–í–û–î–ò–¢ CSV
—Å–æ–∑–¥–∞—é —Ñ–∞–π–ª –∏ –ø–∞–ø–∫—É

```python
test_content = "–ü—Ä–∏–≤–µ—Ç, –º–∏—Ä! –ü—Ä–∏–≤–µ—Ç!!!"
Path("data").mkdir(exist_ok=True)  # —Å–æ–∑–¥–∞–µ–º –ø–∞–ø–∫—É data –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
Path("data/input.txt").write_text(test_content, encoding="utf-8")
```

—á—Ç–µ–Ω–∏–µ –¥—Ä—É–≥–æ–π –∫–æ–¥–∏—Ä–æ–≤–∫–∏

```python
def read_text(path: str | Path, encoding: str = "cp1251") -> str:
    p = Path(path)
    return p.read_text(encoding=encoding)
strcp1251=(read_text("data/inputcp1251.txt",encoding='windows-1251'))
print(strcp1251)
```
![alt text](img/image4/04.0111.png)

–ø—É—Å—Ç–æ–π txt, —Å–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π, –æ—à–∏–±–∫–∏

```python
str_empty=read_text("data/input_empty.txt")
print(str_empty)

strUTF=read_text("data/input.txt")
print(strUTF)

strcp1251_unicodeerror =(read_text("data/inputcp1251.txt",encoding='utf-32'))
print(strcp1251_unicodeerror)#UnicodeDecodeError

print(read_text("data/input_notfound.txt"))#FileNotFoundError
```

![alt text](img/image4/04.011.png)
![alt text](img/image4/04.012.png)
![alt text](img/image4/04.013.png)

```python
a=read_text("data/json.json")
write_csv(a,'data/json2.csv')

a=read_text("data/input.txt")
write_csv(a,'data/json2.json')
```

![alt text](img/image4/04.0223.png)
![alt text](img/image4/04.0222.png)

—Å–æ–∑–¥–∞–Ω–∏–µ –ø—É—Å—Ç–æ–≥–æ —Å—Å–≤ + –∑–∞–≥–æ–ª–æ–≤–∫–∞, —Ç–µ—Å—Ç —Å—Å–≤ —Å –∑–∞–≥–æ–ª–æ–≤–∫–æ–º, –æ—à–∏–±–∫–∏ –¥–ª–∏–Ω—ã

```python
write_csv([], "data/empty.csv", header=("–ø—É—Å—Ç–æ"))
write_csv([("word","count"),("test",3)], "data/check.csv")
write_csv([("word","count"),("test",3,"errorrr")], "data/checkvalueerror.csv")#valueerror
```
–≤—ã–≤–æ–¥ –≤ —Ç–µ—Ä–º–∏–Ω–∞–ª —Å—Å–≤
```python
def print_csv(path):
    p=Path(path)
    #r —ç—Ç–æ read
    with p.open('r', encoding='utf-8') as f:
        for line in f:
            print(line.strip()) 
print_csv("data/check.csv")
```
![alt text](img/image4/04.014.png)

## –ó–∞–¥–∞–Ω–∏–µ 2
```python
from text import normalize,tokenize
from collections import Counter
from io_txt_csv import write_csv, read_text

def frequencies_from_text(text: str) -> dict[str, int]:
    from text import normalize, tokenize
    tokens = tokenize(normalize(text))
    return Counter(tokens)  # dict-like

def sorted_word_counts(freq: dict[str, int]) -> list[tuple[str, int]]:
    return sorted(freq.items(), key=lambda kv: (-kv[1], kv[0]))
```
–ø—Ä–µ–≤—Ä–∞—Ç–∏–ª–∏ –≤ —Å—Ç—Ä–æ–∫–∏ –∏–∑ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã—Ö —Å–ª–æ–≤ –∏ —á–∞—Å—Ç–æ—Ç 

```python
text=sorted_word_counts(frequencies_from_text(read_text("data/input.txt")))
write_csv(text, "data/report.csv", header=("word", "count"))
```
–Ω–∞—à –Ω–æ–≤—ã–π —Å—Å–≤

![alt text](img/image4/04.021.png)

```python
inputt = read_text("data/input.txt")
tokens = (tokenize(normalize(inputt)))
dictt=Counter(tokens)
sorted_freq = sorted_word_counts(dictt)

print(f"–í—Å–µ–≥–æ —Å–ª–æ–≤: {len(tokens)}")
print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {len(dictt)}")
print(f"–¢–æ–ø-5:")
for word, count in sorted_freq[:5]:
    print(f"{word}:{count}")
```
![alt text](img/image4/04.022.png)

–∫—Ä–∞–µ–≤—ã–µ —Å–ª—É—á–∞–∏ –ø–æ —Ç–∏–ø—É –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª –±—É–¥—É—Ç —Ä–∞–±–æ—Ç–∞—Ç—å
# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 5
## –ó–∞–¥–∞–Ω–∏–µ 1

—Ñ—É–Ω–∫—Ü–∏—è

```python

from pathlib import Path
import csv
import json  

def json_to_csv(json_path: str, csv_path: str) -> None:
    #–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ñ–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω—ã—Ö –∏ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    p_json = Path(json_path)
    if p_json.suffix.lower() != '.json':
        raise ValueError('–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –Ω–µ json')
    p_csv = Path(csv_path)
    if p_csv.suffix.lower() != '.csv':
        raise ValueError('–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –Ω–µ csv')
    #—á—Ç–µ–Ω–∏–µ json –∏ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ, utf-8
    try:
        with p_json.open('r', encoding='utf-8') as f:
            list_dicts=json.load(f)
    except FileNotFoundError:
        raise FileNotFoundError
    except UnicodeDecodeError:
        raise UnicodeDecodeError
    except json.JSONDecodeError:
        raise ValueError("–≤–æ–æ–±—â–µ –ø—É—Å—Ç–æ–π —Ñ–∞–π–ª")
    #—Å–ª–æ–≤–∞—Ä–∏ –ª–∏ —ç—Ç–æ
    for item in list_dicts:
        if not isinstance(item, dict):
            raise ValueError("–Ω–µ —Å–ª–æ–≤–∞—Ä–∏")
    #–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ—Ç—É
    if len(list_dicts)==0:
        raise ValueError("–ø—É—Å—Ç–æ–π json —Ç–∏–ø–∞ {}")
    
    original_count = len(list_dicts)

    #–ø–æ–∏—Å–∫ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤
    fieldnames = set()
    for item in list_dicts:
        fieldnames.update(item.keys())
    fieldnames = list(fieldnames)
    #–∑–∞–ø–∏—Å—Ç—å csv
    with p_csv.open('w',encoding='utf-8', newline='') as f:
        #–ø—É—Å—Ç–æ—Ç—ã –∑–∞–ø–æ–ª–Ω—è–µ–º
        res=csv.DictWriter(f,fieldnames=fieldnames,restval='–ø—É—Å—Ç–æ')
        res.writeheader()
        for row in list_dicts:
            res.writerow(row)
    
    with p_csv.open('r', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            csv_count = len(list(reader))
            if original_count != csv_count:
                raise ValueError("–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –Ω–µ —Å–æ–≤–ø–∞–ª–æ")

```

–ø—Ä–æ–≤–µ—Ä–∫–∏

```python
#—à–∞–±–ª–æ–Ω–Ω–∞—è –∑–∞–ø–∏—Å—å –∏ —á—Ç–µ–Ω–∏–µ
data = [{"name": "Alice", "age": 22}, {"name": "Bob", "age": 25}, {"name": "John"}]
path = Path("data/people.json")
with path.open('w', encoding='utf-8') as i:
    json.dump(data, i ,ensure_ascii=False, indent=2)
#–±–∞–∑–∞, –ø—É—Å—Ç–æ–π, –Ω–µ —Å–ª–æ–≤–∞—Ä—å, –Ω–µ —Å—É—â, –Ω–µ utf-8
json_to_csv("data/people.json", "data/people.csv")
json_to_csv("data/peopleempty.json", "data/people2.csv")
json_to_csv("data/peoplenotdict.json", "data/people2.csv")
json_to_csv("data/peoplenotexcist.json", "data/people2.csv")
json_to_csv("data/people1251.json", "data/people2.csv")
```
![alt text](img/image5/1.11.png)
![alt text](img/image5/1.12.png)

–Ω–æ –µ—Å–ª–∏ –≤ —Ñ–∞–π–ª–µ –±—É–¥–µ—Ç {} –∏–ª–∏ [] —Ç–æ —Ç–æ–∂ –æ—à–∏–±–∫–∞

![alt text](img/image5/1.2.png)
![alt text](img/image5/1.3.png)
![alt text](img/image5/1.4.png)
![alt text](img/image5/1.5.png)
```python
def csv_to_json(csv_path: str, json_path: str) -> None:
    #–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ñ–æ—Ä–º–∞—Ç –≤—Ö–æ–¥–Ω—ã—Ö –∏ –≤—ã—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    p_csv = Path(csv_path)
    if p_csv.suffix.lower() != '.csv':
        raise ValueError('–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –Ω–µ csv')
    p_json = Path(json_path)
    if p_json.suffix.lower() != '.json':
        raise ValueError('–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –Ω–µ json')
    try:
        with p_csv.open('r', encoding='utf-8') as f:
            #—Å—á–∏—Ç–∞–µ—Ç –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É –∫–∞–∫ –∑–∞–≥–æ–ª–æ–≤–∫–∏
            reader = csv.DictReader(f)
            if not reader.fieldnames:
                raise ValueError('–Ω–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏–ª–∏ –ø—É—Å—Ç–æ–π')
            data = [row for row in reader]
    except FileNotFoundError:
        raise FileNotFoundError
    except UnicodeDecodeError:
        raise UnicodeDecodeError
    with p_json.open('w',encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    if len(json.load(p_json.open('r',encoding='utf-8')))!= len(data):
        raise ValueError("–∫–æ–ª-–≤–æ –∑–∞–ø–∏—Å–µ–π –Ω–µ —Å–æ–≤–ø–∞–ª–æ")

rows = [
    {"name": "Alice", "age": "22", "city": "SPB"},
    {"name": "Bob", "age": "25", "city": "Moscow"}
]
with open("data/peoplein.csv", "w", newline="", encoding="utf-8") as f:
    fieldnames = rows[0].keys()
    ress = csv.DictWriter(f, fieldnames=fieldnames)
    ress.writeheader()
    ress.writerows(rows)
csv_to_json("data/peoplein.csv","data/peopleout.json")
csv_to_json("data/peopleempty.csv", "data/people2.json")
csv_to_json("data/no_header.csv", "data/people2.json")
csv_to_json("data/peoplenotexcist.csv", "data/people2.json")
csv_to_json("data/people1251.csv", "data/people2.json")
```

![alt text](img/image5/2.11.png)
![alt text](img/image5/2.12.png)
![alt text](img/image5/2.2.png)
![alt text](img/image5/2.3.png)
![alt text](img/image5/2.4.png)
![alt text](img/image5/2.5.png)
## –ó–∞–¥–∞–Ω–∏–µ 2
```python
import csv
from pathlib import Path
import xlsxwriter

def csv_to_xlsx(csv_path: str, xlsx_path: str) -> None:
    p_csv = Path(csv_path) 
    if p_csv.suffix.lower() != '.csv':
        raise ValueError('–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –Ω–µ csv')
    p_xlsx = Path(xlsx_path)
    if p_xlsx.suffix.lower() != '.xlsx':
        raise ValueError('–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –Ω–µ xlsx')
    try:
        with p_csv.open('r', encoding='utf-8') as f:
            reader = csv.reader(f)
            data = list(reader)
    except FileNotFoundError:
        raise FileNotFoundError
    except UnicodeDecodeError:
        raise UnicodeDecodeError
    if len(data) == 0:
        raise ValueError("–ø—É—Å—Ç–æ–π")
    original_count = len(data)
    # —Å–æ–∑–¥–∞–Ω–∏–µ xlsx —Ñ–∞–π–ª–∞
    workbook = xlsxwriter.Workbook(xlsx_path)
    worksheet = workbook.add_worksheet("Sheet1")
    # –∞–≤—Ç–æ—à–∏—Ä–∏–Ω–∞ –∫–æ–ª–æ–Ω–æ–∫
    if data:
        #–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –º–∞–∫—Å –¥–ª–∏–Ω—É –∏–∑ —Å–ø–∏—Å–∫–æ–≤
        for col_idx in range(max(len(row) for row in data)):
            #–º–∞–∫—Å –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —è—á–µ–π–∫–∞–º –∏–∑ —Å—Ç—Ä–æ–∫–∏
            max_width = max(len(str(row[col_idx] if col_idx < len(row) else "")) for row in data)
            worksheet.set_column(col_idx, col_idx, max(8, max_width + 2))
    #–∑–∞–ø–∏—Å—å –¥–∞–Ω–Ω—ã—Ö –≤ xlsx
    written_count = 0
    for row_idx, row in enumerate(data):
        for col_idx, value in enumerate(row):
            worksheet.write(row_idx, col_idx, value)
        written_count += 1
    #–∑–∞–∫—Ä—ã–≤–∞–µ–º
    workbook.close()

    if original_count != written_count:
        raise ValueError("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –Ω–µ —Å–æ–≤–ø–∞–ª–æ")

csv_to_xlsx("data/people.csv", "data/people.xlsx")
csv_to_xlsx("data/peopleempty.csv", "data/people2.xlsx")
csv_to_xlsx("data/peoplenotexcist.csv", "data/people2.xlsx")
csv_to_xlsx("data/people1251.csv", "data/people2.xlsx")
```
![alt text](img/image5/3.3333.png)
![alt text](img/image5/3.2.png)
![alt text](img/image5/3.4.png)
![alt text](img/image5/3.5.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 6
## –∫–æ–¥1

```python
import argparse
from lab03.text import tokenize, count_freq, top_n

def main():
    # —Å–æ–∑–¥–∞–µ–º –æ—Å–Ω–æ–≤—É
    parser = argparse.ArgumentParser(description="CLI‚Äë—É—Ç–∏–ª–∏—Ç—ã –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–æ–π ‚Ññ6")
    #—Å–æ–∑–¥–∞—é –∞—Ä–≥—É–º–µ–Ω—Ç—ã 
    subparsers = parser.add_subparsers(dest="command")

    # –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ cat - –≤—ã–≤–æ–¥ —Ñ–∞–π–ª–∞ –ø–æ—Å—Ç—Ä–æ—á–Ω–æ
    cat_parser = subparsers.add_parser("cat", help="–í—ã–≤–µ—Å—Ç–∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞")
    #–∞—Ä–≥—É–µ–Ω—Ç—ã –ø–æ–¥–∫–æ–º–∞–Ω–¥—ã input –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∏ –≤—ã–≤–æ–¥–∞ –±–µ–∑ –Ω—É–º–µ—Ä–∞—Ü–∏–∏ –∏ n –¥–ª—è –Ω—É–º–µ—Ä–∞—Ü–∏–∏–∏
    cat_parser.add_argument("--input", required=True, help="–ø—É—Ç—å –∫ —Ñ–∞–π–ª—É")
    cat_parser.add_argument("-n", action="store_true", help="–ù—É–º–µ—Ä–æ–≤–∞—Ç—å —Å—Ç—Ä–æ–∫–∏")

    # –ø–æ–¥–∫–æ–º–∞–Ω–¥–∞ stats - –∞–Ω–∞–ª–∏–∑
    stats_parser = subparsers.add_parser("stats", help="–ß–∞—Å—Ç–æ—Ç—ã —Å–ª–æ–≤")
    #–∞—Ä–≥—É–º–µ–Ω—Ç—ã input –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –∏ –≤—ã–≤–æ–¥–∞ –≤—Å–µ–π —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏ top –¥–ª—è —Ç–æ–ø–∞..
    stats_parser.add_argument("--input", required=True, help="–ø—É—Ç—å –∫ —Ñ–∞–π–ª—É")
    stats_parser.add_argument("--top", type=int, default=5, help="—Ç–æ–ø —Å–ª–æ–≤")

    args = parser.parse_args()

    if args.command == "cat":
        try:
            with open(args.input, encoding="utf-8") as f:
            #–Ω—É–º–µ—Ä—É–µ–º —Å 1 –≤ —Ñ–æ—Ä–º–∞—Ç–µ –Ω–æ–º–µ—Ä: —Å—Ç—Ä–æ–∫–∞
                for i, line in enumerate(f, start=1):
                    if args.n:
                        print(f"{i}: {line.rstrip()}")
                    else:
                        print(line.rstrip())
        except FileNotFoundError:
            parser.error("—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        except Exception as e:
            parser.error("–æ—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ —Ñ–∞–π–ª–∞")
        
    #
    elif args.command == "stats":
        try:
            with open(args.input, encoding="utf-8") as f:
                text = f.read()
            tokens = tokenize(text)
            freqs = count_freq(tokens)
            for word, count in top_n(freqs, args.top):
                print(f"{word}: {count}")
        except FileNotFoundError:
            parser.error(f"–§–∞–π–ª '{args.input}' –Ω–µ –Ω–∞–π–¥–µ–Ω")
        except Exception as e:
            parser.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–π–ª–∞: {e}")
    
    else:
        parser.print_help()
```
—Å—Ç—Ä—É–∫—Ç—É—Ä–∞(?)

![alt text](img/image6/6.1.png)

![alt text](img/image6/6.11.png)

–≤—ã–≤–æ–¥ —Å—Ç—Ä–æ–∫–∏ cat

![alt text](img/image6/6.2.png)

–≤—ã–≤–æ–¥ —Ç–æ–ø–∞ stats

![alt text](img/image6/6.3.png)

–¥—Ä—É–≥–æ–π —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö

![alt text](img/image6/6.4.png)

## –∫–æ–¥2
```python
import argparse
import os
from json_csv import json_to_csv, csv_to_json
from csv_xlsx import csv_to_xlsx

def main():
    parser = argparse.ArgumentParser(description="–ö–æ–Ω–≤–µ—Ä—Ç–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö")
    sub = parser.add_subparsers(dest="cmd")

    p1 = sub.add_parser("json2csv",help="json –≤ csv")
    # –ø–æ–¥–∞—Ä–≥—É–º–µ–Ω—Ç—ã in –∏ out –¥–ª—è args –≤—Ö–æ–¥–Ω—ã—Ö –∏ –≤—ã—Ö–æ–¥–Ω—ã—Ö
    p1.add_argument("--in", dest="input", required=True, help="–ø—É—Ç—å –¥–ª—è json")
    p1.add_argument("--out", dest="output", required=True, help="–ø—É—Ç—å –¥–ª—è csv")

    p2 = sub.add_parser("csv2json",help="–ø—É—Ç—å csv –≤ json")
    p2.add_argument("--in", dest="input", required=True,help="–ø—É—Ç—å –¥–ª—è csv")
    p2.add_argument("--out", dest="output", required=True,help="–ø—É—Ç—å –¥–ª—è json")

    p3 = sub.add_parser("csv2xlsx",help="–ø—É—Ç—å csv –≤ xlsx")
    p3.add_argument("--in", dest="input", required=True,help="–ø—É—Ç—å –¥–ª—è csv")
    p3.add_argument("--out", dest="output", required=True,help="–ø—É—Ç—å –¥–ª—è xlsx")

    args = parser.parse_args()
    #–ø—Ä–æ–≤–µ—Ä–∫–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
    if not os.path.exists(args.input):
        parser.error("–≤—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω.")

    #–≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–¥–∫–æ–º–∞–Ω–¥
    try:
        #–µ—Å–ª–∏ –∫–æ–º–∞–Ω–¥–∞ —Ç–∞–∫–∞—è —Ç–æ —Ç–∞–∫–∞—è —Ç–æ, —Ç–æ –∏–∑ 5 –ª–∞–±—ã
        if args.cmd == "json2csv":
            json_to_csv(args.input, args.output)
        elif args.cmd == "csv2json":
            csv_to_json(args.input, args.output)
        elif args.cmd == "csv2xlsx":
            csv_to_xlsx(args.input, args.output)
        print(f"–£—Å–ø–µ—à–Ω–æ: {args.input} -> {args.output}")
    except Exception as e:
        parser.error("–æ—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏–∏")

if __name__ == "__main__":
    main()
```

json –≤ csv

![alt text](img/image6/6.5.png)

![alt text](img/image6/6.6.png)

csv –≤ json (–±–µ–∑ —Ñ–æ—Ç–æ —Ç–∞–º —Ç–∞–∫–∂–µ)

![alt text](img/image6/6.7.png)

csv –≤ xlsx 

![alt text](img/image6/6.8.png)

![alt text](img/image6/6.9.png)

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 7

# —Ç–µ—Å—Ç–∏–∫–∏ –Ω–∞ —Ç–µ–∫—Å—Ç
```python
import pytest
from src.lab03.text import normalize, tokenize, count_freq, top_n

# NORMALIZE


@pytest.mark.parametrize(
    "source, expected",
    [
        # –∫–∏—Ä–∏–ª–ª–∏—Ü–∞, —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
        ("–ü—Ä–ò–≤–ï—Ç\n–ú–ò—Ä\t", "–ø—Ä–∏–≤–µ—Ç –º–∏—Ä"),
        # –±—É–∫–≤–∞ —ë
        ("—ë–∂–∏–∫, –Å–ª–∫–∞", "–µ–∂–∏–∫ –µ–ª–∫–∞"),
        # –ª–∞—Ç–∏–Ω–∏—Ü–∞, —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
        ("Hello\r\nWorld", "hello world"),
        # –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        ("  –¥–≤–æ–π–Ω—ã–µ   –ø—Ä–æ–±–µ–ª—ã  ", "–¥–≤–æ–π–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã"),
        # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        ("", ""),
        # —Ç–æ–ª—å–∫–æ —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
        ("!@#$%^&*()", ""),
        # —Ü–∏—Ñ—Ä—ã
        ("Test123 Numbers456", "test numbers"),
        # —Å–º–µ—à–∞–Ω–Ω—ã–π —Å–ª—É—á–∞–π
        ("Mixed Test!", "mixed test"),
    ],
)
def test_normalize_basic(source, expected):
    assert normalize(source) == expected


# TOKENIZE
@pytest.mark.parametrize(
    "source, expected",
    [
        # –±–∞–∑–æ–≤—ã–π —Å–ª—É—á–∞–π
        ("–ø—Ä–∏–≤–µ—Ç –º–∏—Ä —Ç–µ—Å—Ç", ["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä", "—Ç–µ—Å—Ç"]),
        # –æ–¥–Ω–æ —Å–ª–æ–≤–æ
        ("–æ–¥–∏–Ω", ["–æ–¥–∏–Ω"]),
        # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞
        ("", []),
        # —Ç–æ–ª—å–∫–æ –ø—Ä–æ–±–µ–ª—ã
        ("   \t\n  ", []),
        # –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        ("  –¥–≤–∞   —Å–ª–æ–≤–∞  ", ["–¥–≤–∞", "—Å–ª–æ–≤–∞"]),
        # –ª–∞—Ç–∏–Ω–∏—Ü–∞
        ("hello world test", ["hello", "world", "test"]),
    ],
)
def test_tokenize_basic(source, expected):
    assert tokenize(source) == expected


@pytest.mark.parametrize(
    "tokens, expected",
    [
        # –±–∞–∑–æ–≤—ã–π —Å–ª—É—á–∞–π
        (["–ø—Ä–∏–≤–µ—Ç", "–º–∏—Ä", "–ø—Ä–∏–≤–µ—Ç"], {"–ø—Ä–∏–≤–µ—Ç": 2, "–º–∏—Ä": 1}),
        # –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
        ([], {}),
        # –æ–¥–Ω–æ —Å–ª–æ–≤–æ
        (["—Å–ª–æ–≤–æ"], {"—Å–ª–æ–≤–æ": 1}),
        # –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
        (["a", "a", "a", "a"], {"a": 4}),
        # –Ω–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–º
        (["hello", "world", "hello"], {"hello": 2, "world": 1}),
    ],
)
def test_count_freq(tokens, expected):
    assert count_freq(tokens) == expected


@pytest.mark.parametrize(
    "freq_dict, n, expected",
    [
        # –±–∞–∑–æ–≤—ã–π —Å–ª—É—á–∞–π
        ({"–ø—Ä–∏–≤–µ—Ç": 3, "–º–∏—Ä": 2, "—Ç–µ—Å—Ç": 1}, 2, [("–ø—Ä–∏–≤–µ—Ç", 3), ("–º–∏—Ä", 2)]),
        # n –±–æ–ª—å—à–µ —á–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤
        ({"–ø—Ä–∏–≤–µ—Ç": 3, "–º–∏—Ä": 2}, 5, [("–ø—Ä–∏–≤–µ—Ç", 3), ("–º–∏—Ä", 2)]),
        # n = 0
        ({"–ø—Ä–∏–≤–µ—Ç": 3, "–º–∏—Ä": 2}, 0, []),
        # –ø—É—Å—Ç–æ–π —Å–ª–æ–≤–∞—Ä—å
        ({}, 3, []),
        # –æ–¥–Ω–æ —Å–ª–æ–≤–æ
        ({"—Å–ª–æ–≤–æ": 5}, 1, [("—Å–ª–æ–≤–æ", 5)]),
    ],
)
def test_top_n_basic(freq_dict, n, expected):
    assert top_n(freq_dict, n) == expected
```

# —Ç–µ—Å—Ç–∏–∫–∏ –Ω–∞ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤

tmp_path: Path - –≤—Ä–µ–º–µ–Ω–Ω–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è, —Å–æ–∑–¥–∞–≤–∞–µ–º–∞—è pytest


```python
import pytest
import json
import csv
from pathlib import Path
from src.lab05.json_csv import json_to_csv, csv_to_json

# –ë–ê–ó–ê


def test_json_to_csv_roundtrip(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = [
        {"name": "Alice", "age": 22},
        {"name": "Bob", "age": 25},
    ]
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    json_to_csv(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    assert len(rows) == 2
    assert {"name", "age"} <= set(rows[0].keys())


def test_csv_to_json_roundtrip(tmp_path: Path):
    src = tmp_path / "data.csv"
    dst = tmp_path / "data.json"

    csv_data = [
        {"name": "Alice", "age": "22", "city": "Moscow"},
        {"name": "Bob", "age": "25", "city": "London"},
    ]

    with src.open("w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["name", "age", "city"])
        writer.writeheader()
        writer.writerows(csv_data)
    csv_to_json(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        result_data = json.load(f)

    assert len(result_data) == 2
    assert result_data[0]["name"] == "Alice"
    assert result_data[1]["age"] == 25  # –î–æ–ª–∂–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å—Å—è –≤ —á–∏—Å–ª–æ


# –ü–£–°–¢–´–ï
def test_json_to_csv_empty_json(tmp_path: Path):
    src = tmp_path / "empty.json"
    dst = tmp_path / "empty.csv"

    src.write_text("[]", encoding="utf-8")

    with pytest.raises(ValueError, match="–ø—É—Å—Ç–æ–π json"):
        json_to_csv(str(src), str(dst))


def test_csv_to_json_empty_csv(tmp_path: Path):
    src = tmp_path / "empty.csv"
    dst = tmp_path / "empty.json"

    src.write_text("", encoding="utf-8")

    with pytest.raises(ValueError, match="–Ω–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏–ª–∏ –ø—É—Å—Ç–æ–π"):
        csv_to_json(str(src), str(dst))


# –ù–ê –§–û–†–ú–ê–¢–´


def test_json_to_csv_wrong_input_format(tmp_path: Path):
    src = tmp_path / "data.txt"
    dst = tmp_path / "data.csv"

    src.write_text("some text", encoding="utf-8")

    with pytest.raises(ValueError, match="–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –Ω–µ json"):
        json_to_csv(str(src), str(dst))


def test_json_to_csv_wrong_output_format(tmp_path: Path):
    src = tmp_path / "data.json"
    dst = tmp_path / "data.txt"

    src.write_text("[]", encoding="utf-8")

    with pytest.raises(ValueError, match="–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –Ω–µ csv"):
        json_to_csv(str(src), str(dst))


def test_csv_to_json_wrong_input_format(tmp_path: Path):

    src = tmp_path / "data.txt"
    dst = tmp_path / "data.json"

    src.write_text("some text", encoding="utf-8")

    with pytest.raises(ValueError, match="–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –Ω–µ csv"):
        csv_to_json(str(src), str(dst))


def test_csv_to_json_wrong_output_format(tmp_path: Path):
    src = tmp_path / "data.csv"
    dst = tmp_path / "data.txt"

    with src.open("w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["name"])
        writer.writeheader()

    with pytest.raises(ValueError, match="–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –≤—ã—Ö–æ–¥–Ω–æ–π —Ñ–æ—Ä–º–∞—Ç –Ω–µ json"):
        csv_to_json(str(src), str(dst))


# –ù–ï –°–£–©–ï–°–¢–í–£–ï–¢


def test_csv_to_json_file_not_found():
    with pytest.raises(FileNotFoundError):
        csv_to_json("nonexistent.csv", "output.json")


def test_json_to_csv_file_not_found():
    with pytest.raises(FileNotFoundError):
        json_to_csv("nonexistent.json", "output.csv")


# –ö–û–õ–í–û –ó–ê–ü–ò–°–ï–ô –°–û–í–ü–ê–î–ê–ï–¢
def test_json_to_csv_record_count(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = [
        {"name": "Alice", "age": 22},
        {"name": "Bob", "age": 25},
        {"name": "Charlie", "age": 30},
    ]
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    json_to_csv(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    assert len(rows) == 3


def test_csv_to_json_record_count(tmp_path: Path):
    src = tmp_path / "data.csv"
    dst = tmp_path / "data.json"

    csv_data = [
        {"name": "Alice", "age": "22"},
        {"name": "Bob", "age": "25"},
        {"name": "Charlie", "age": "30"},
        {"name": "David", "age": "35"},
    ]

    with src.open("w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["name", "age"])
        writer.writeheader()
        writer.writerows(csv_data)
    csv_to_json(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        result_data = json.load(f)

    assert len(result_data) == 4


# –ü–†–û–í–ï–†–ö–ê –ó–ê–ì–û–õ–û–í–ö–û–í
def test_json_to_csv_field_names(tmp_path: Path):
    src = tmp_path / "people.json"
    dst = tmp_path / "people.csv"
    data = [
        {"name": "Alice", "age": 22, "city": "Moscow"},
        {"name": "Bob", "age": 25, "city": "London"},
    ]
    src.write_text(json.dumps(data, ensure_ascii=False, indent=2), encoding="utf-8")
    json_to_csv(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        rows = list(csv.DictReader(f))

    assert set(rows[0].keys()) == {"name", "age", "city"}


def test_csv_to_json_field_names(tmp_path: Path):
    src = tmp_path / "data.csv"
    dst = tmp_path / "data.json"

    csv_data = [
        {"name": "Alice", "age": "22", "city": "Moscow", "country": "Russia"},
        {"name": "Bob", "age": "25", "city": "London", "country": "UK"},
    ]

    with src.open("w", encoding="utf-8", newline="") as f:
        writer = csv.DictWriter(f, fieldnames=["name", "age", "city", "country"])
        writer.writeheader()
        writer.writerows(csv_data)
    csv_to_json(str(src), str(dst))

    with dst.open(encoding="utf-8") as f:
        result_data = json.load(f)

    assert set(result_data[0].keys()) == {"name", "age", "city", "country"}
```

–≤—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—à–ª–∏

![alt text](<img/image 7/1.png>)

# —Å—Ç–∏–ª—å —Ç–æ–∂–µ —Å—É–ø–µ—Ä

![alt text](<img/image 7/2.png>)

# pyproject 

```python
[build-system]
requires = ["setuptools >= 77.0.3"] # –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
build-backend = "setuptools.build_meta" # —Å–±–æ—Ä–∫–∞ 

[project]
name = "python-labs" # –∏–º—è 
dynamic = ["version"] # –≤–µ—Ä—Å–∏—è

dependencies = [
    "pandas>=2.2", # –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö
    "openpyxl>=3.0", # –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è —ç–∫—Å–µ–ª—è
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0", # –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
    "pytest-cov>=5.0", # –¥–ª—è –ø–æ–∫—Ä—ã—Ç–∏—è 
    "black>=24.0", # –¥–ª—è —Å—Ç–∏–ª—è
    "ruff>=0.6" # –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
]

[tool.black]
line-length = 88 # –º–∞–∫—Å –¥–ª–∏–Ω–∞ —Å—Ç—Ä–æ–∫–∏
target-version = ["py38"] # —Å–∏–Ω—Ç–∞–∫—Å–∏—Å –ø–∏—Ç–æ–Ω–∞ –≤–µ—Ä—Å–∏–∏ 3.8
```

# –õ–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è —Ä–∞–±–æ—Ç–∞ 8

## –∫–æ–¥—ã
``` python
from dataclasses import dataclass
from datetime import datetime, date


@dataclass
class Student:
    fio: str
    birthdate: str
    group: str
    gpa: float

    def __post_init__(self):

        if not isinstance(self.fio, str):
            raise TypeError(f"–Ω–µ str")
        if not isinstance(self.birthdate, str):
            raise TypeError(f"–Ω–µ str")
        if not isinstance(self.group, str):
            raise TypeError(f"–Ω–µ str")
        if not isinstance(self.gpa, (int, float)):
            raise TypeError(f"–Ω–µ float")

        try:
            datetime.strptime(self.birthdate, "%Y-%m-%d")
        except ValueError:
            raise ValueError(
                f"–Ω–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã: '{self.birthdate}' –æ–∂–∏–¥–∞–µ—Ç—Å—è YYYY-MM-DD"
            )

        if not (0 <= self.gpa <= 5):
            raise ValueError(f"GPA {self.gpa} –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 0 –¥–æ 5")

    def age(self) -> int:
        birth_date = datetime.strptime(self.birthdate, "%Y-%m-%d").date()
        today = date.today()
        age = today.year - birth_date.year

        if (today.month, today.day) < (birth_date.month, birth_date.day):
            age -= 1

        return age

    def to_dict(self) -> dict:
        return {
            "fio": self.fio,
            "birthdate": self.birthdate,
            "group": self.group,
            "gpa": self.gpa,
        }

    @classmethod
    def from_dict(cls, d: dict):
        required_fields = ["fio", "birthdate", "group", "gpa"]
        for field in required_fields:
            if field not in d:
                raise ValueError(f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–ª–µ: {field}")

        return cls(
            fio=d["fio"], birthdate=d["birthdate"], group=d["group"], gpa=d["gpa"]
        )

    def __str__(self):
        return f"–°—Ç—É–¥–µ–Ω—Ç: {self.fio}, –ì—Ä—É–ø–ø–∞: {self.group}, GPA: {self.gpa:.2f}, –í–æ–∑—Ä–∞—Å—Ç: {self.age()} –ª–µ—Ç"
```

```python
import json
from typing import List
from pathlib import Path
from .models import Student


def students_to_json(students: List[Student], path: str) -> None:
    if not students:
        raise ValueError("—Å–ø–∏—Å–æ–∫ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º")

    if not isinstance(students, list):
        raise TypeError(f"–æ–∂–∏–¥–∞–µ—Ç—Å—è —Å–ø–∏—Å–æ–∫")

    for student in students:
        if not isinstance(student, Student):
            raise TypeError

    try:
        data = [student.to_dict() for student in students]
    except Exception as e:
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–∏ —Å—Ç—É–¥–µ–Ω—Ç–æ–≤: {e}")

    file_path = Path(path)
    file_path.parent.mkdir(parents=True, exist_ok=True)

    with open(path, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)


def students_from_json(path: str) -> List[Student]:
    if not Path(path).exists():
        raise FileNotFoundError(f"—Ñ–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
    
    try:
        with open(path, "r", encoding="utf-8") as f:
            data = json.load(f)
    except json.JSONDecodeError:
        raise json.JSONDecodeError
    except UnicodeDecodeError:
        raise ValueError(f"–Ω–µ json")

    if not isinstance(data, list):
        raise ValueError

    students = []
    for item in data:
        if not isinstance(item, dict):
            raise ValueError(f"–Ω–µ —Å–ª–æ–≤–∞—Ä—å")
        
        student = Student.from_dict(item)
        students.append(student)
    return students
```

–ø—Ä–æ–≤–µ—Ä–∫–∏

–ø—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∑–∞–ø–∏—Å–∏ –±–µ–∑ –∫–∞–∫–æ–≥–æ—Ç–æ –∞—Ä–≥—É–º–µ–Ω—Ç–∞ –≤—ã–≤–æ–¥–∏—Ç—Å—è –æ—à–∏–±–∫–∞, –æ–Ω–∞ –∏–¥–µ—Ç –ø–µ—Ä–µ–¥ postinit, –ø–æ—ç—Ç–æ–º—É —è –µ—ë –Ω–µ —Ç—Ä–æ–≥–∞–ª–∞
```python
student3 = Student(
    fio="–ü–µ—Ç—Ä–æ–≤–∞ –ê–Ω–Ω–∞ –°–µ—Ä–≥–µ–µ–≤–Ω–∞",
    birthdate="2001-08-22",
    group="AI-03",

)
```

```python
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'src'))

from lab08.models import Student
from lab08.serialize import students_to_json, students_from_json

print("–±–∞–∑–æ–≤—ã–π —Å—Ç—É–¥–µ–Ω—Ç:")
student1 = Student(
    fio="–ò–≤–∞–Ω–æ–≤ –ò–≤–∞–Ω –ò–≤–∞–Ω–æ–≤–∏—á",
    birthdate="2000-05-15",
    group="SE-01",
    gpa=4.2
)
print(f"{student1}")

print("\n–¢–µ—Å—Ç to_dict/from_dict:")
student_dict = student1.to_dict()
print(f"to_dict: {student_dict}")
student_from_dict = Student.from_dict(student_dict)
print(f"from_dict: {student_from_dict}")

# print("\nGPA")
# Student(
#     fio="–ü–µ—Ç—Ä–æ–≤–∞ –ê–Ω–Ω–∞",
#     birthdate="2001-08-22",
#     group="AI-03",
#     gpa="zkzkz"
# )

# print("\nGPA")
# Student(
#     fio="–ü–µ—Ç—Ä–æ–≤–∞ –ê–Ω–Ω–∞",
#     birthdate="2001-08-22",
#     group="AI-03",
#     gpa=6.0
# )

# print("\n–Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –¥–∞—Ç–∞")
# Student(
#     fio="–°–∏–¥–æ—Ä–æ–≤ –ê–ª–µ–∫—Å–µ–π",
#     birthdate="2001/08/22",
#     group="CS-02",
#     gpa=3.5
# )

print("\n—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è:")
student2 = Student(
    fio="–ü–µ—Ç—Ä–æ–≤–∞ –ê–Ω–Ω–∞ –°–µ—Ä–≥–µ–µ–≤–Ω–∞",
    birthdate="2001-08-22",
    group="AI-03",
    gpa=4.8
)

students_to_json([student1, student2], "data/lab08/students_output.json")
print("—É—Ä–∞ JSON")

print("\n–¥–µ—Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è:")
loaded = students_from_json("data/lab08/students_output.json")

for s in loaded:
    print(f"{s}")
```

![alt text](img/image8/3.png)
![alt text](img/image8/image.png)
![alt text](<img/image8/image copy.png>)
![alt text](<img/image8/image copy 2.png>)